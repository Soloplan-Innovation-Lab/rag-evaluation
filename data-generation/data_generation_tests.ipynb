{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DOCUMENTS_PATH = os.getcwd() + r\"/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader(DOCUMENTS_PATH)\n",
    "documents = loader.load()\n",
    "\n",
    "for document in documents:\n",
    "    document.metadata['filename'] = document.metadata['source']\n",
    "    document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current tests to generate synthetic data to evaluate the RAG pipeline. The synthetic data (in this case) consists of a question and an answer.\n",
    "The generation works like this: all documents (in this case all custom functions for DevExpress formulas) are iterated and the desired amount of test data is created. It randomly uses the documents (or multiple documents if needed) to create the question and answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from custom_evolutions import formula_evolution\n",
    "\n",
    "try:\n",
    "    import sys\n",
    "    sys.path.append('/workspace')\n",
    "    from internal_shared.models.ai import azure_model, critic_llm, azure_embeddings\n",
    "except ImportError:\n",
    "    print(\"No shared package found, using local package\")\n",
    "\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    azure_model,\n",
    "    critic_llm,\n",
    "    azure_embeddings\n",
    ")\n",
    "\n",
    "# generate testset\n",
    "testset = generator.generate_with_langchain_docs(documents, test_size=10, distributions={formula_evolution: 1.0}, with_debugging_logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "df = testset.to_pandas()\n",
    "\n",
    "# get current timestamp\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "# export as csv\n",
    "df.to_csv(f\"testset_{timestamp}.csv\", sep=\";\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
